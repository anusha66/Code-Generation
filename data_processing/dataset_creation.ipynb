{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/home/anushap/Code-Generation-Old/pandas_context_dataset_5years_no_dups_filtered_nl2code_FINAL.pkl','rb')\n",
    "data_nl = pickle.load(f)\n",
    "\n",
    "f = open('/home/anushap/Code-Generation-Old/pandas_context_dataset_5years_no_dups_filtered_code2code_FINAL.pkl','rb')\n",
    "data_code = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51928"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51928"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['### we do need to know that an escape sequence represents a single character'], [\"first_result.find('strong').text[0:-1] + ', 2017'  \"]) ([\"first_result.find('strong').text[0:-1]\"], [\"first_result.find('strong').text[0:-1] + ', 2017'  \"])\n"
     ]
    }
   ],
   "source": [
    "print(data_nl[1],data_code[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.arange(len(data_nl))\n",
    "np.random.shuffle(order)\n",
    "#pickle.dump(order,open('shuffle_order.pkl','wb'))\n",
    "#random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51928\n"
     ]
    }
   ],
   "source": [
    "#order = pickle.load(open('shuffle_order.pkl','rb'))\n",
    "print(len(order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = []\n",
    "code = []\n",
    "code_code = []\n",
    "code_nl = []\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in order:\n",
    "    \n",
    "    temp1 = ' '.join(data_nl[i][0])\n",
    "    nl.append(temp1.replace(' \\n',' $').replace('\\n',' $'))\n",
    "    nll = temp1.replace(' \\n',' $').replace('\\n',' $')\n",
    "    \n",
    "    temp2 = ' '.join(data_nl[i][1])\n",
    "    code_nl.append(temp2.replace(' \\n',' $').replace('\\n',' $'))\n",
    "    \n",
    "    temp1 = ' '.join(data_code[i][0])\n",
    "    code.append(temp1.replace(' \\n',' $').replace('\\n',' $'))\n",
    "    codee = temp1.replace(' \\n',' $').replace('\\n',' $')\n",
    "    \n",
    "    temp2 = ' '.join(data_code[i][1])\n",
    "    code_code.append(temp2.replace(' \\n',' $').replace('\\n',' $'))\n",
    "    tgt = temp2.replace(' \\n',' $').replace('\\n',' $')\n",
    "    \n",
    "    data.append((nll,codee,tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51928"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('### most common dog type',\n",
       " \"with open('tweet_json.txt', 'w') as outfile:  $     json.dump(df3_list, outfile)\",\n",
       " \"plt.hist(full_clean_df['type']) $ plt.ylabel('Number of Doggies') $ plt.xlabel('Dog Type') $ plt.title('Which Dog Type is the Most Common')\")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    lis = []\n",
    "    for j in range(len(data[i])):\n",
    "            lis.append(data[i][j])\n",
    "        \n",
    "    new_data.append(' '.join(lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51928"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_set = list(set(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51927"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "for i in range(len(new_data_set)):\n",
    "    \n",
    "    index.append(new_data.index(new_data_set[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = []\n",
    "\n",
    "for i in range(len(index)):\n",
    "    \n",
    "    final_data.append(data[index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_data)\n",
    "data = final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('information on the options for the mar encoder are found in its documention. when i ran the unique address list, it took about 5 minutes. $ we can read the mar encoded data back into a dataframe and join the data to our condos dataframe. $',\n",
       " \"condos = pd.merge(condos, mar, left_on='FULLADDRESS',  right_on='full_address')\",\n",
       " 'condos.shape')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data1 = []\n",
    "new_data2 = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    lis1 = []\n",
    "    lis2 = []\n",
    "    for j in range(len(data[i])):\n",
    "        if j ==0 or j==2:\n",
    "            lis1.append(data[i][j])\n",
    "        if j==1 or j==2:\n",
    "            lis2.append(data[i][j])\n",
    "    new_data1.append(' '.join(lis1))\n",
    "    new_data2.append(' '.join(lis2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51839\n",
      "51839\n"
     ]
    }
   ],
   "source": [
    "print(len(new_data1))\n",
    "print(len(new_data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51839\n",
      "51835\n"
     ]
    }
   ],
   "source": [
    "print(len(set(new_data1)))\n",
    "print(len(set(new_data2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'information on the options for the mar encoder are found in its documention. when i ran the unique address list, it took about 5 minutes. $ we can read the mar encoded data back into a dataframe and join the data to our condos dataframe. $ condos.shape'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"condos = pd.merge(condos, mar, left_on='FULLADDRESS',  right_on='full_address') condos.shape\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "index1 = []\n",
    "new_data_set1 = list(set(new_data1))\n",
    "for i in range(len(new_data_set1)):\n",
    "    \n",
    "    index1.append(new_data1.index(new_data_set1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2 = []\n",
    "new_data_set2 = list(set(new_data2))\n",
    "for i in range(len(new_data_set2)):\n",
    "    \n",
    "    index2.append(new_data2.index(new_data_set2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51835 51839\n"
     ]
    }
   ],
   "source": [
    "print(len(index2),len(index1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(set(index1).intersection(set(index2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51838 0\n"
     ]
    }
   ],
   "source": [
    "print(max(index),min(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51835"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = []\n",
    "\n",
    "for i in range(len(index)):\n",
    "        final_data.append(data[index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51835\n"
     ]
    }
   ],
   "source": [
    "order = np.arange(len(final_data))\n",
    "np.random.shuffle(order)\n",
    "pickle.dump(order,open('shuffle_order.pkl','wb'))\n",
    "#random.shuffle(data)\n",
    "print(len(order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = []\n",
    "code = []\n",
    "code_code = []\n",
    "code_nl = []\n",
    "\n",
    "\n",
    "for i in order:\n",
    "    \n",
    "    nl.append(final_data[i][0])\n",
    "    code.append(final_data[i][1])\n",
    "    \n",
    "    code_code.append(final_data[i][2])\n",
    "    code_nl.append(final_data[i][2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## import data \n",
      " intervention_test['CRE_DATE_GZL'].min(), intervention_test['CRE_DATE_GZL'].max() \n",
      " print(intervention_history.shape) $ print(intervention_train.shape) $ print(intervention_test.shape) \n",
      " intervention_test['CRE_DATE_GZL'].min(), intervention_test['CRE_DATE_GZL'].max()\n"
     ]
    }
   ],
   "source": [
    "print(nl[1],'\\n',code_nl[1],'\\n',code[1],'\\n',code_code[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51835 51835\n"
     ]
    }
   ],
   "source": [
    "print(len(nl),len(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41468"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0.80*len(nl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46651"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0.80*len(nl)+0.1*len(nl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there are several other data formats that can be imported into python and converted into dataframes, with the help of buitl-in or third-party libraries. these include json, xml, hdf5, non-relational databases, and various web apis.'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl[41470]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nl_train.txt', 'w') as f:\n",
    "    for item in nl[0:int(0.80*len(nl))]:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open('code_train.txt', 'w') as f:\n",
    "    for item in code_nl[0:int(0.80*len(nl))]:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nl_dev.txt', 'w') as f:\n",
    "    for item in nl[int(0.80*len(nl)):int(0.80*len(nl)+0.1*len(nl))]:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open('code_dev.txt', 'w') as f:\n",
    "    for item in code_nl[int(0.80*len(nl)):int(0.80*len(nl)+0.1*len(nl))]:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nl_test.txt', 'w') as f:\n",
    "    for item in nl[int(0.80*len(nl)+0.1*len(nl)):]:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open('code_test.txt', 'w') as f:\n",
    "    for item in code_nl[int(0.80*len(nl)+0.1*len(nl)):]:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nl_train.txt', 'w') as f:\n",
    "    for item in code[0:int(0.80*len(nl))]:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open('code_train.txt', 'w') as f:\n",
    "    for item in code_code[0:int(0.80*len(nl))]:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open('nl_dev.txt', 'w') as f:\n",
    "    for item in code[int(0.80*len(nl)):int(0.80*len(nl)+0.1*len(nl))]:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open('code_dev.txt', 'w') as f:\n",
    "    for item in code_code[int(0.80*len(nl)):int(0.80*len(nl)+0.1*len(nl))]:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open('nl_test.txt', 'w') as f:\n",
    "    for item in code[int(0.80*len(nl)+0.1*len(nl)):]:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open('code_test.txt', 'w') as f:\n",
    "    for item in code_code[int(0.80*len(nl)+0.1*len(nl)):]:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
